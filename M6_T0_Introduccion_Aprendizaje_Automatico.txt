{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj3Td2DKv3sQ"
      },
      "source": [
        "# **Aprendizaje Automático**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT1o5VPccmPn"
      },
      "source": [
        "![Return of the Jedi](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Returnofthejedi-logo2.svg/1920px-Returnofthejedi-logo2.svg.png)\n",
        "\n",
        "Fuente de la imagen: https://es.wikipedia.org\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Índice**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "14gTc8nrbNya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [Aprendizaje Automático](#scrollTo=xj3Td2DKv3sQ)\n",
        "<br>\n",
        ">>\n",
        ">> [1 - Introducción al Aprendizaje Automático](#scrollTo=7u7OCgp7bHGS) \\\\\n",
        ">> [2 - Tipologías de Tareas](#scrollTo=7u7OCgp7bHGS) \\\\\n",
        ">>>[2.1. Tareas Predictivas](#scrollTo=8tjM5ItJtQt1) \\\\\n",
        ">>>[2.2. Tareas Descriptivas](#scrollTo=krXaM2TbtWtv) \n",
        ">>\n",
        ">> [3 - Preparación de los Datos y Modelos de Representación](#scrollTo=kwDb5GXj4eID) \n",
        ">>>[3.1. Modelos de Representación](#scrollTo=Osl_i5R14uHI) \\\\\n",
        ">>>[3.2. Preparación de los Datos](#scrollTo=XTyvl4Hd5c9X) \n",
        ">>\n",
        ">> [4 - Métodos de Aprendizaje Automático](#scrollTo=ptAEVBCdw254)\n",
        ">>>[4.1. Métodos Perezosos de Aprendizaje Automático](#scrollTo=ccWWlGjcxJHy) \\\\\n",
        ">>>[4.2. Métodos Anticipativos de Aprendizaje Automático](#scrollTo=NP6NQwxkxQQB) \\\\\n",
        ">>>[4.3. Meta-clasificadores](#scrollTo=Z8kmRs_VxlmG) \n",
        ">>\n",
        ">> [5 - Evaluación](#scrollTo=E6Yrm8z_xkXy)\n",
        ">>>[5.1. Evaluación de Clasificadores](#scrollTo=di2VeGaUVmUw) \\\\\n",
        ">>>[5.2. Evaluación de Modelos de Regresión](#scrollTo=pfiDNb90VqKK) \\\\\n",
        ">>>[5.3. Evaluación de Modelos de Agrupamiento (Clustering)](#scrollTo=Fn1G2WqPVqEa) \\\\\n",
        ">>>[5.4. Evaluación de Reglas de Asociación](#scrollTo=1NqwABPbVpye) \\\\\n",
        ">>>[5.5. Sobreajuste y Subajuste](#scrollTo=GEHjsPd9vWPF)\n",
        ">>\n",
        ">> [IDEAS CLAVE](#scrollTo=lSdsrq7ReWMc) \n",
        "\n",
        "<br>\n",
        "\n",
        "< [Índice Global]() | \n",
        "[1 - Árboles de Decisión]() >"
      ],
      "metadata": {
        "id": "HDK4UtO3bQnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Introducción al Aprendizaje Automático**\n",
        "\n",
        "En [Clark y Boswell, 2000] se define la **Minería de Datos** como el proceso de extraer conocimiento útil y comprensible, previamente desconocido, desde grandes cantidades de datos almacenados en distintos formatos. De dicha definición se desprenden algunos hechos a considerar:\n",
        "\n",
        "* El resultado de la minería de datos debe ser **conocimiento nuevo**.\n",
        "\n",
        "* Dicho conocimiento debe ser **inteligible** y susceptible de **generar valor** para la toma de decisiones. Que el conocimiento deba ser inteligible no significa que el modelo de aprendizaje lo sea; por ejemplo, una red neuronal es opaca en cuanto a su funcionamiento, pero su resultado puede aportar conocimiento para determinar el riesgo de una operación bursátil.\n",
        "\n",
        "* La entrada del proceso es una **gran cantidad de datos** en diversos formatos, a partir de los cuales se deberá extraer el conocimiento. Este punto es una de las bases que enlaza a la minería de datos con el *big data*.\n",
        "\n",
        "* Y aunque no se menciona de manera explícita en la definición, el proceso de minería se debe realizar de manera **(semi) automática**.\n",
        "\n",
        "La minería de datos tiene relación con diversas disciplinas, confundiéndose en ocasiones con algunas de ellas. Se puede considerar a la **estadística** como la madre de la minería de datos, ya que gran cantidad de terminología, métodos y técnicas provienen de ella: las medidas de centralidad como la media, la desviación estándar, las distribuciones de frecuencias, los métodos de validación cruzada o el aprendizaje bayesiano son algunas de ellas. El **aprendizaje automático** también tiene una relación estrecha con la minería de datos, ya que proporciona algoritmos que son capaces de aprender a partir de ejemplos para resolver tareas concretas. La **inteligencia artificial** en su concepto más amplio tiene relación con la minería de datos pues le aporta todo lo relativo al aprendizaje automático, pero también los modelos de representación de los datos necesarios para que dichos algoritmos puedan aprender. Pero quizás donde existe una relación más estrecha, tanto que llega a confundir la terminología, es con el proceso de extracción de conocimiento de bases de datos (***KDD*** de sus siglas en inglés ***Knowledge Discovery in Databases***).\n",
        "\n",
        "![INTRO_KDD](https://tecno-academy.s3.eu-west-1.amazonaws.com/ML/DT/proceso_KDD.jpg \"Proceso de KDD\")\n",
        "\n",
        "<small>*FUENTE: https://www.laboratoriodecertificacion.es/*</small>\n",
        "\n",
        "<br/>\n",
        "<p><mark>NOTA</mark></p>\n",
        "<hr>\n",
        "\n",
        "Aunque el foco de este módulo y el siguiente es el aprendizaje automático, hay ciertos aspectos de la minería de datos que es importante abordar como la preparación de los datos y la evaluación posterior de los modelos para dar un sentido holístico al propio aprendizaje automático.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7u7OCgp7bHGS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-GfNVudRiMo"
      },
      "source": [
        "# **2. Tipologías de Tareas**\n",
        "\n",
        "Los problemas más comunes a los que nos enfrentamos en un proyecto de minería de datos son los que determinarán las técnicas de aprendizaje automático necesarias para modelar dicho problema. En general, podemos clasificar estos problemas en dos tipos de tareas:\n",
        "\n",
        "* **Predictivas**: tratan de predecir nuevos valores a partir del entrenamiento previo con datos etiquetados.\n",
        "* **Descriptivas**: parten de un conjunto de valores no etiquetados y tratan de describirlos.\n",
        "\n",
        "Para ver ambas de ellas, vamos a dar algunas premisas y definiciones. Sea:\n",
        "\n",
        "\n",
        "* $E$ el conjunto de todos los posibles elementos de entrada, representando generalmente como un conjunto de atributos nominales o numéricos $A$.\n",
        "* $A$ el conjunto de atributos nominales o numéricos de $E$ tal que $E=A_1 \\times A_2 \\times ... \\times A_n$.\n",
        "* $e € E$ el elemento ejemplo perteneciente a $E$ y representado por la tupla $e=<a_1, a_2, ..., a_n>$ donde $a € A$.\n",
        "* $S$ el conjunto de valores de salida.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.1. Tareas Predictivas**\n",
        "\n",
        "En las tareas predictivas se dispone de un conjunto $d$ de elementos etiquetados como duplas $d=<e,s>$ donde $e € E$ y $s € S$. \n",
        "\n",
        "Se dice que el conjunto $d$ está etiquetado puesto que a cada entrada $e$ se sabe su correspondencia unívoca con un elemento de salida $s$. Por ejemplo, clientes con y sin riesgo, opiniones positivas, negativas o neutras, o sensores y sus rangos de valores. \n",
        "\n",
        "Dentro de este tipo de tareas podemos encontrarnos con problemas de **clasificación**, **categorización**, **priorización** y **regresión**.\n",
        "\n",
        "###**2.1.1. Clasificación**\n",
        "\n",
        "Su objetivo es aprender una función $f:E->S$ que a partir de un conjunto de elementos de entrada etiquetados $d=<e,s>$ sea capaz de predecir el valor de la etiqueta para una nueva instancia no etiquetada. Por ejemplo, dado un conjunto de clientes $E$\n",
        "representados por una serie de atributos $A$ (e.g., edad, ingresos, gastos, nivel educativo, etc.) y un conjunto $S$ de etiquetas asignadas (e.g., riesgo/no riesgo), sea capaz de predecir la etiqueta $s$ correspondiente para un nuevo cliente $e$ para el que no se dispone de etiqueta.\n",
        "\n",
        "Si el conjunto $S$ sólo tiene un valor (y generalmente su contrario), se habla de **clasificadores binarios** (e.g. es o no *spam*, es o no cliente de riesgo, es hombre o mujer). Si por el contrario hay más de un valor (e.g. positivo, negativo y neutro; adolescente, veinteañero, treintañero, etc.), se habla de **clasificadores multiclase**. Estos últimos se pueden entrenar para predecir entre las múltiples clases, o como clasificadores binarios entre cada clase y las demás (estrategia 1 contra\n",
        "todos).\n",
        "\n",
        "La salida de la clasificación puede llevar asociada una estimación de la probabilidad de que dicha clasificación sea la correcta (e.g. este cliente es potencialmente de riesgo con 85% de certeza). Esto es lo que se conoce como **clasificación suave**, donde además de la función de estimación de clase, se aprende otra función con la probabilidad de pertenencia a la misma. Es lo que se conoce como el **estimador de probabilidad**. Además de la ventaja que aporta el conocer el grado de certeza de la predicción, este tipo de clasificadores permiten su  combinación mediante *ranking* de clasificadores.\n",
        "\n",
        "###**2.1.2. Categorización**\n",
        "\n",
        "En este caso, en lugar de aprender una función que asigna cada ejemplo $e$ una clase en exclusiva, en la categorización se pueden asignar tantas clases como sea necesario. Un ejemplo típico de esta tarea es la de etiquetado semántico, donde por\n",
        "ejemplo, a una entrada de un blog se le asignarían tantas etiquetas como temáticas se detectasen en el mismo. De igual manera que con los clasificadores, en la categorización se puede aprender un estimador de probabilidad y por lo tanto realizar una **categorización suave**.\n",
        "\n",
        "Se puede ver el problema de la categorización como un problema agregado de clasificadores binarios, donde para cada categoría se dispondría de un clasificador binario que asignaría o no la\n",
        "categoría correspondiente. Volviendo al ejemplo del blog, si se dispone de tres etiquetas o temáticas, la categorización por clasificadores binarios consistiría en aprender tres clasificadores que determinasen si el blog pertenece o no a cada una de esas etiquetas.\n",
        "\n",
        "###**2.1.3. Priorización**\n",
        "\n",
        "El problema es similar al de la clasificación/categorización, pero se basa en obtener una lista ordenada de preferencias a partir de los datos, habiendo aprendido previamente de ejemplos ordenados. La dificultad estriba precisamente en el aprendizaje\n",
        "de estas secuencias de elementos, pero el trasfondo es similar a los casos anteriores.\n",
        "\n",
        "Una aplicación interesante sería en los sistemas de recomendación, donde se proporciona al usuario una lista de elementos afines a sus gustos, pero dicha lista se presenta ordenada. Piénsese en resultados de una búsqueda y la recomendación de consultas similares, o la elección\n",
        "de un producto (no sólo un producto físico a comprar, también uno virtual a consumir como una canción o una película), donde los productos similares recomendados estuvieran ordenados por\n",
        "afinidad a las preferencias del usuario.\n",
        "\n",
        "###**2.1.4. Regresión**\n",
        "\n",
        "La definición matemática es similar a la de la clasificación, es decir, aprender una función que asigne un único valor de salida a cada ejemplo de entrada $d:E->S$. Sin embargo, la diferencia fundamental es que los valores de $S$ sólo pueden ser numéricos, a\n",
        "diferencia de la clasificación, donde los valores de $S$ son atributos nominales denominados clases. Esta propiedad de la regresión permite trabajar en un espacio continuo como es el\n",
        "de los números reales $R$, y la función de predicción puede ser tan compleja como sea necesaria, no sólo lineal.\n",
        "\n",
        "La regresión puede servir para predecir las ventas del próximo trimestre dependiendo de una serie de factores actuales, o para identificar la edad que tiene una persona en función de otras\n",
        "características como el lenguaje que utiliza. Aunque los valores resultantes son numéricos y pueden estar en un rango continuo, se puede fácilmente convertir un problema de regresión en uno de clasificación simplemente creando rangos que se correspondan con determinadas clases. Así pues, una regresión para identificar la edad de una persona podría convertirse en una clasificación si creamos rangos como niños (de 0 a 13 años), adolescentes (de 13 a 18 años), jóvenes (de 18 a 25 años), etcétera."
      ],
      "metadata": {
        "id": "8tjM5ItJtQt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.2. Tareas Descriptivas**\n",
        "\n",
        "En el caso de las tareas descriptivas, los ejemplos $e € E$ se presentan sin etiquetar ni ordenar, o lo hacen de manera parcial. Ejemplos de tareas descriptivas son el **agrupamiento**, la  **correlación**, las **reglas de asociación** y la **detección de anomalías**.\n",
        "\n",
        "###**2.2.1. Agrupamiento**\n",
        "\n",
        "También conocido por su denominación inglesa (*clustering*), consiste en obtener conjuntos de elementos que sean lo más homogéneos dentro del conjunto y lo más heterogéneos con respecto al resto de grupos. Esto es, conjuntos de elementos que se parezcan mucho entre sí y poco con respecto a los demás.\n",
        "\n",
        "La principal diferencia con la clasificación es que a priori no se sabe cada elemento a qué conjunto pertenece, ni siquiera los conjuntos que puede haber. Es el proceso de aprendizaje el que decide ambas cosas: qué grupos hay (y por lo tanto cuántos) y quién pertenece a cada grupo.\n",
        "\n",
        "Una aplicación de este tipo de técnicas es la segmentación de clientes en marketing. Según determinados comportamientos (atributos), se procede a agruparlos según determinadas características comunes y diferentes al resto. Cuando se dispone de un nuevo cliente, se calcula a qué grupo pertenecería, y se podría inferir atributos (comportamientos) de dicho cliente que no\n",
        "conocemos a priori por la similitud con los otros clientes de su grupo.\n",
        "\n",
        "En las técnicas de agrupamiento también existe el concepto de suave y de estimador de probabilidad, con lo que cada instancia o ejemplo de entrada no sólo se asignaría al correspondiente grupo (el más probable), sino que se dispondría de la probabilidad de pertenencia a cada uno de los grupos, lo que permitiría al supervisor humano tener mayor conocimiento de lo que está sucediendo, e incluso incorporar correctores.\n",
        "\n",
        "###**2.2.2. Correlación**\n",
        "\n",
        "El objetivo es determinar si dos instancias o elementos $<e1, e2> € E$, o alguno de sus atributos $E = A_1 \\times A_2 \\times ... \\times A_n$, está relacionado de algún modo, y cuál es la dirección de dicha relación.\n",
        "\n",
        "La correlación se limita a atributos numéricos, y generalmente el resultado se determina por un valor numérico indicando la similitud o diferencia entre ambos, que suele comprenderse en el rango $[-1, 1]$. Un valor que tiende hacia el extremo izquierdo $(-1)$ indicará una correlación negativa donde al crecer una variable, la otra decrece, mientras que un valor que tiende hacia el extremo derecho $(1)$ indicará correlación positiva, donde una variable crecerá si lo hace la otra. Valores cercanos a $0$ implican no correlación entre ellos, es decir, cualquier relación es fruto del azar.\n",
        "\n",
        "Es importante hacer notar que la correlación únicamente determina la relación entre dos elementos, nunca la causalidad. Esto significa que son bidireccionales y no orientados, a diferencia de la causalidad, que implicaría unidireccionalidad y orientación. Esta confusión es uno de los errores más cometidos en análisis de datos, especialmente en entornos *big data* donde, por la sobreabundancia de datos, se pueden encontrar correlaciones entre cualquier par de variables (correlaciones espurias).\n",
        "\n",
        "###**2.2.3. Reglas de Asociación**\n",
        "\n",
        "Las reglas de asociación permiten obtener relación entre variables\n",
        "cuyos atributos son nominales, a diferencia de la correlación que únicamente lo permitía con atributos numéricos. Las reglas de asociación se han aplicado principalmente a descubrir patrones en bases de datos, y han sido y son una de las principales tareas en minería de datos. Con ellas se pueden obtener reglas del tipo \"*si compró este producto hay tanta probabilidad de comprar este otro*\". Existe una regla de asociación muy famosa que se desprende de un estudio realizado por *Wal-Mart* que afirmaba que \"*los clientes que compran pañales son 5,33 veces más propensos a comprar cerveza (que los que no compran pañales)*\". Este hecho, quizás debido a las largas noches de los padres primerizos, aportó un conocimiento sustancial a *Wal-Mart* para reorganizar sus estanterías y poner ambos productos más cerca, aumentando así sus ventas.\n",
        "\n",
        "Además de poderse aplicar a atributos nominales, las reglas de asociación tienen otra diferencia sustancial con la correlación, y es que en este caso sí que puede existir implicación causal. Es decir, las reglas de asociación pueden ser bidireccionales, o unidireccionales y orientadas. En esta categoría se suelen incluir las dependencias funcionales, diferenciándose en que éstas consideran todos los posibles valores. Por ejemplo, sabiendo el nivel de ingresos, el rango de edad, la etnia, el nivel de estudio y si está casado, se puede determinar el riesgo de morosidad de un cliente.\n",
        "\n",
        "###**2.2.4. Detección de Anomalías**\n",
        "\n",
        "La detección de valores e instancias anómalas, a diferencia de la mayoría de los métodos anteriores donde se aprende por la existencia de determinados patrones que se hacen patentes por su frecuencia de aparición conjunta, esta tarea consiste en encontrar aquellos valores, o aquellas instancias (ejemplos), que no sean similares a ninguna de las demás.\n",
        "\n",
        "Esta tarea se suele utilizar para detectar fraudes, fallos o intrusos en sistemas, comportamientos extraños y/o diferenciados, etcétera. Por ejemplo, fraudes en el uso de tarjetas de crédito porque el momento, el lugar y/o el importe sean anómalos con respecto a su uso normal, fallos en las redes de transmisión porque el nivel de ruido, la latencia y/o el orden de llegada de los paquetes sea diferente a su distribución normal, intento de acceso no autorizado al sistema porque la combinación de caracteres utilizados en la contraseña, el número de intentos y/o el intervalo entre intentos difieren de los usos anteriores, o detección de pederastas porque el estilo de escritura, la\n",
        "frecuencia y/o las palabras utilizadas no se correspondan con el perfil del usuario que dice ser."
      ],
      "metadata": {
        "id": "krXaM2TbtWtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><mark>RECUERDA</marm></p>\n",
        "<hr>\n",
        "\n",
        "* Las **tareas predictivas** son aquellas que, a partir de ejemplos etiquetados, permiten predecir la clase, etiqueta o valor de nuevos ejemplos no vistos anteriormente.\n",
        "\n",
        "* Las **tareas descriptivas** son aquellas que, a partir de ejemplos no etiquetados, los describen, agrupan, asocian o detectan valores anómalos en ellos."
      ],
      "metadata": {
        "id": "eAHB5MbOhkHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Preparación de los Datos y Modelos de Representación**\n",
        "\n",
        "Tras la definición de la tarea (problema) a resolver y la identificación de en qué tipo de problema de minería de datos se encuadra, es el momento de preparar los datos para poder aplicar las técnicas de modelado correspondiente. \n",
        "\n",
        "La preparación de los datos va a involucrar dos fases bien diferenciadas: el **pre-procesamiento** y la **representación**. Se presentan en orden inverso para mejorar su comprensión.\n",
        "\n"
      ],
      "metadata": {
        "id": "kwDb5GXj4eID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3.1. Modelos de Representación**\n",
        "\n",
        "Para poder aplicar las diferentes técnicas de aprendizaje automático que veremos en el siguiente punto, se deben representar los objetos sobre los que se quiera construir el modelo mediante lo que se conoce como **modelo de espacio vectorial**. \n",
        "\n",
        "Por ejemplo, si el problema que queremos resolver es el de predecir si un nuevo cliente tiene riesgo de ser moroso, el objeto sobre el que realizaremos la\n",
        "minería será el objeto cliente. Este objeto vendrá definido por una serie de características como su sexo, edad, nivel salarial, nivel educacional, lugar de residencia, puesto en la organización, tamaño de la organización en la que trabaja, etcétera.\n",
        "\n",
        "![INTRO_client](https://tecno-academy.s3.eu-west-1.amazonaws.com/ML/DT/object_client.png \"Objeto tipo CLIENTE\")\n",
        "\n",
        "<small>*FUENTE: Elaboración propia*</small>\n",
        "\n",
        "\n",
        "La representación vectorial de un cliente vendrá dada por los valores que tomará cada uno de los atributos que lo definen. Por ejemplo,\n",
        "\n",
        "$$ Francisco = \\{hombre, 45, ?, doctor, valencia\\} $$\n",
        "\n",
        "La representación anterior se denomina vectorial porque convierte cada objeto en un vector de características definidas por su valor concreto para ese ejemplo concreto. Es por ello que a este proceso se le denomina de **extracción de características**. Se puede apreciar en el ejemplo anterior que existen diferentes tipos de características, concretamente:\n",
        "\n",
        "* Características **numéricas**, que pueden ser enteras o reales, limitadas o no a un intervalo, como es el caso de la edad.\n",
        "\n",
        "* Características **nominales**, con o sin orden, como pueden ser el resto de características del modelo: sexo, nivel salarial, nivel educacional, lugar de residencia.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Osl_i5R14uHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3.2. Preparación de los Datos**\n",
        "\n",
        "Generalmente los datos de los que disponemos para construir el espacio vectorial de los objetos a minar no suele estar adecuado a los requerimientos del algoritmo que vamos a utilizar, pese a que en la fase *ETL* se haya realizado limpieza y normalización de los mismos. Por ejemplo, algunos algoritmos no trabajan bien, o incluso lo imposibilitan, con valores faltantes y/o nulos (como el salario en el caso del ejemplo). Otros algoritmos sólo permiten trabajar con atributos numéricos, mientras que otros no permiten utilizar más que atributos nominales. A continuación enumeramos algunas de las técnicas que se suelen aplicar para pre-procesar los datos y adecuarlos a los\n",
        "requerimientos de modelado.\n",
        "\n",
        "* **Discretización**: Permite convertir atributos numéricos a nominales, mediante lo que se conoce como técnicas de *binning*. Para ello los atributos numéricos se agrupan en rangos predefinidos y se asigna la etiqueta correspondiente. Ejemplo de discretización lo hemos visto en el caso del nivel salarial o el tamaño de la organización, donde en lugar de un valor numérico absoluto tenemos la pertenencia a uno de esos rangos.\n",
        "\n",
        "* **Numerización**: Permite convertir atributos nominales a numéricos, generalmente asignando valores numéricos consecutivos a los diferentes valores nominales de la característica. Esto es necesario en casos como el análisis multivariante o la regresión lineal, que sólo trabajan con atributos numéricos.\n",
        "\n",
        "* **Valores faltantes**: En ocasiones los algoritmos no trabajan bien con valores faltantes por lo que se deben convertir a valores aptos para el modelo. Por ejemplo, si de un cliente no tenemos su nivel salarial, se podría crear una etiqueta más que indique que no se conoce (*NSC*) para que el modelo pudiera tratar con dichos valores.\n",
        "\n",
        "* **Reducción de la dimensionalidad**: Cuando el modelo vectorial es muy grande, porque se dispone de muchos atributos, es posible que necesitemos reducir la dimensionalidad porque los algoritmos de minería no trabajen bien con tantas características (aumenten considerablemente el coste computacional). Esto suele suceder en problemas de alta dimensionalidad como son el tratamiento de imágenes, donde una representación vectorial puede consistir en los valores RGB-alfa para cada uno de los millones píxeles de una imagen, o en  procesamiento del lenguaje natural donde una representación vectorial puede\n",
        "consistir en la frecuencia de aparición de cada palabra del texto. Existen múltiples técnicas de reducción de la dimensionalidad, de entre las que destacan las técnicas basadas en **entropía** (se seleccionan aquellas características que más novedad aportan al modelo), las basadas en **ganancia de información** (similar a las anteriores, son aquellas características que aportan más información), o el **análisis de componentes principales** o ***PCA (Principal Component Analysis)*** (que efectúa una proyección a un espacio multimensional de menor dimensionalidad que el original pero manteniendo la relevancia de los atributos)."
      ],
      "metadata": {
        "id": "XTyvl4Hd5c9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><mark>IMPORTANTE</mark></p>\n",
        "<hr>\n",
        "\n",
        "Antes de abordar el aprendizaje automático hay que revisar los datos y prepararlos para que sean adecuados tanto a la tarea a abordar como al método de aprendizaje a utilizar."
      ],
      "metadata": {
        "id": "7XNp2qYLiT1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Métodos de Aprendizaje Automático**\n",
        "\n",
        "También conocidas como **Técnicas de Modelado** ya que, una vez identificado el tipo de problema al que nos enfrentamos, debemos decidir con qué algoritmo construir el modelo con el que aproximar su solución. De manera general, se puede considerar que hay dos tipos de aproximaciones algorítmicas al aprendizaje automático: **retardada** (o perezosa, de ***lazy learning***) y **anticipativa** (o ansiosa, de ***eager learning***).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ptAEVBCdw254"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.1. Métodos Perezosos de Aprendizaje Automático**\n",
        "\n",
        "En el caso perezoso, el algoritmo de aprendizaje automático espera hasta disponer del ejemplo sobre el que aplicar el conocimiento (clasificación, regresión, etc.). \n",
        "\n",
        "Una de sus principales **ventajas** es que resuelve los problemas de manera local, según se van produciendo los ejemplos, lo que permite adaptarse de manera rápida y sencilla a los ejemplos sobre los que tiene que trabajar.\n",
        "Esto es así porque no requiere de un entrenamiento previo, que puede resultar costoso, y que puede sobreajustar el algoritmo a los datos de entrenamiento, perdiendo capacidad de generalización a nuevos ejemplos. \n",
        "\n",
        "Una de sus principales **desventajas** es que a cada nuevo ejemplo el algoritmo debe reaprender, frente a un método anticipativo que únicamente debe aplicar los cálculos aprendidos, con lo que se puede ver reducido su rendimiento, algo crítico especialmente en entornos big data. \n",
        "\n",
        "Uno de los algoritmos perezosos más conocidos es el de los **k-vecinos más próximos** (***k-nearest neighbours***). Otros algoritmos son la regresión logística local o el razonamiento basado en casos, las k-medias (*k-means*), los mapas autoorganizativos de *Kohonen*, o *LVQ* (*Learning Vector Quantisation*)."
      ],
      "metadata": {
        "id": "ccWWlGjcxJHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.2. Métodos Anticipativos de Aprendizaje Automático**\n",
        "\n",
        "En el caso anticipativo, el algoritmo de aprendizaje construye un modelo a partir de un conjunto de datos de entrenamiento, y ante un nuevo ejemplo, aplica el modelo construido para resolver el problema (e.g., clasificación, regresión, etc.). \n",
        "\n",
        "Una de sus principales **ventajas** es el alto rendimiento a la hora de aplicarlo en producción, ya que el modelo ya está aprendido y aplicarlo sobre ejemplos nuevos es muy rápido. \n",
        "\n",
        "Sin embargo, su **principal inconveniente** es la posibilidad de sobreajuste a las muestras de entrenamiento, con lo que si las muestras sobre las que aplicar el modelo varían significativamente, puede que su precisión se vea mermada. Para minimizar este problema, se suele reentrenar el modelo cada cierto tiempo para adaptarlo a la variabilidad en los datos.\n",
        "\n",
        "A continuación, se describen brevemente las aproximaciones al aprendizaje automático anticipativo más conocidas. Sin embargo, existen multitud de técnicas diferentes. El campo de la minería de datos y el aprendizaje automático es muy amplio y activo en la investigación, por lo que se\n",
        "recomienda consultar la bibliografía para ampliar en el tema.\n",
        "\n",
        "* **Métodos Bayesianos**: Se basan en el **teorema de Bayes**, por el cual se puede calcular la probabilidad a posteriori de la clase en base a las probabilidades a priori aprendidas de los datos para cada una de las características que los representan. Los métodos bayesianos son fáciles de programar, son muy expresivos y permiten trabajar con incertidumbre (de\n",
        "hecho, la probabilidad nace para ello). Como ejemplos tendríamos las Redes Bayesianas, Naïve Bayes, o ciertos algorítmos de búsqueda (e.g., K2, B, HC).\n",
        "\n",
        "* **Árboles de Decisión**: Los árboles de decisión permiten aprender en base a ejemplos, mediante la construcción de **reglas de decisión simples** que se disparan según umbrales de una determinada característica. En el proceso de entrenamiento se va dividiendo los ejemplos hasta construir un árbol donde cada división se efectúa en base a un umbral de decisión para una característica determinada (e.g. edad < 40 vs. edad > 40). A la hora de clasificar un nuevo ejemplo se comenzará en el nodo raíz del árbol y se seguirán las condiciones de sus nodos hasta llegar a un nodo hoja, que se corresponderá con una de las posibles clases. Para evitar el sobreajuste al entrenamiento, construyendo árboles que aprendan exactamente los ejemplos de entrada, pero no tengan gran capacidad discriminatoria, se efectúa lo que se llama una poda a un determinado nivel. Como ejemplos tendríamos los algoritmos CART, ID3, J48, o los sistemas de reglas, entre otros.\n",
        "\n",
        "* **Redes neuronales artificiales (*RNA*)**: El origen de las *RNA* fue para intentar emular lo que sucedía en el cerebro humano. Así pues, se definen las neuronas como funciones simples de proceso de una señal de entrada hacia una señal de salida. La neurona se activa cuando la señal de entrada supera un determinado umbral, propagando su valor a la salida, o no lo hace. El entrenamiento se produce por la técnica de ***backpropagation*** que ajusta los pesos o umbrales de cada neurona a partir de los ejemplos dados. A priori, son métodos opacos, poco explicativos, pero que en la actualidad están produciendo buenos resultados en gran variedad de tareas en el campo del ***deep learning***. Como ejemplos tendríamos el Perceptrón simple, el Perceptrón multicapa, las Redes Neuronales Convolucionales (CNN), las Redes Neuronales Recurrentes (RNN), etc.\n",
        "\n",
        "* **Máquinas de Vectores Soporte** (***SVM*** por sus siglas en inglés ***Support Vector Machines***): Tratan de determinar el hiperplano que separa las muestras entre las diferentes clases, de forma que el margen entre la distancia entre las muestras más próximas de cualquier clase y dicho hiperplano se maximice. Las *SVM* hacen uso de métodos basados en ***kernels*** para operar en espacios de alta dimensionalidad, sin necesidad de calcular todos los puntos de manera explícita.\n",
        "\n",
        "* **Algoritmos Evolutivos** (dentro de los cuales se encuentran los **genéticos**): Tratan el problema de la optimización sobre la base de la teoría de la evolución. Se parte de un conjunto de soluciones al problema, soluciones que se cruzan entre sí de manera no determinística, simulando lo que sería una mutación. De entre las nuevas soluciones se seleccionan aquellas que mejores resultados ofrecen (optimización), y se repite el proceso, simulando la reproducción de los individuos más fuertes (soluciones óptimas)."
      ],
      "metadata": {
        "id": "NP6NQwxkxQQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.3. Meta-clasificadores**\n",
        "\n",
        "Siguiendo la filosofía de Epicuro, *“si más de una hipótesis es consistente con los datos, debemos mantenerlas todas”*, los meta-clasificadores permiten combinar los resultados obtenidos por diferentes algoritmos de aprendizaje automático, de modo que la salida del meta-clasificador es una **ponderación** entre las salidas de los diferentes clasificadores y cuyo objetivo es conseguir\n",
        "**sinergia** entre los mismos, es decir, obtener un resultado superior a la utilización individual de cualquiera de ellos.\n",
        "\n",
        "La combinación de clasificadores se puede realizar de múltiples maneras, de forma simplificada, respondiendo al concepto de **voto**. Por ejemplo, un votador mayoritario consistiría en, dado el resultado proporcionado por los diferentes clasificadores, seleccionar aquel resultado que más veces aparece en la salida de los clasificadores individuales. Esto sin embargo obliga a tener un número\n",
        "superior de clasificadores que de clases (problema de multiclasificación), puesto que cada clasificador podría dar un resultado y no haber consenso. Existen diversas técnicas para mejorar el proceso:\n",
        "\n",
        "* Asignación de **pesos** a cada clasificador, de modo que el votador estaría ponderado dando mayor importancia a los clasificadores que se consideren más precisos, como si de un conjunto de asesores se tratara sobre los cuales tenemos depositado un nivel diferente de confianza.\n",
        "\n",
        "* Aprendiendo una **función de voto**, en lugar de optar por el resultado mayoritario. En este caso, el votador se podría sustituir por otro clasificador que, en función de las predicciones realizadas por los clasificadores individuales y la clase real, aprendiera un modelo de votación. La principal ventaja es que dependiendo de los datos el modelo aprenderá un votador ponderado mucho más ajustado que el que le podamos fijar mediante pesos. Sin\n",
        "embargo, su principal desventaja es que estamos acumulando errores de clasificación. Se puede mejorar aprendiendo no sólo a partir de los resultados de los clasificadores individuales, sino además de todas las características que describen a los datos. Por ejemplo, aprendiendo como un clasificador más, y además a partir de las salidas de los anteriores.\n",
        "\n",
        "* **Reordenando la salida de clasificadores suaves**, es decir, si los clasificadores individuales en lugar de proporcionar una salida única, proporcionaran las $n$ mejores predicciones con su porcentaje de certeza, el meta-clasificador podría combinar la salida de todos los clasificadores y reordenarlas en función de posibles pesos. En este caso, sólo tendríamos que aprender la mejor distribución de pesos posibles para el meta-clasificador."
      ],
      "metadata": {
        "id": "Z8kmRs_VxlmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><mark>NOTA</mark></p>\n",
        "<hr>\n",
        "\n",
        "No repasamos aquí el aprendizaje basado en refuerzo por estar más allá de este capítulo introductorio. Sin embargo, se estudiará más en este sentido en próximos capítulos cuando se vean las redes neuronales y las redes neuronales profundas."
      ],
      "metadata": {
        "id": "ahP1FTqfinyC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Yrm8z_xkXy"
      },
      "source": [
        "#**5. Evaluación**\n",
        "\n",
        "La evaluación de los modelos es imprescindible para obtener sus estadísticas de **rendimiento** y poder así compararlos y elegir el mejor para el problema que estamos abordando.\n",
        "\n",
        "Esta evaluación se puede realizar desde múltiples perspectivas. Inicialmente desde dos: la del **coste computacional** de su aplicación, y desde su **capacidad de generalización** y producción de conocimiento útil y aprovechable. En la actualidad, donde los sistemas de inteligencia artificial empiezan a tomar una relevancia importante en todas las áreas de la sociedad y existe un interés (preocupación) creciente en conocer cómo dichos sistemas toman decisiones que afectan a las personas, está empezando a ganar importancia la evaluación de los modelos desde el punto de vista de su **explicabilidad** y/o transparencia (*Explainable AI* o Inteligencia Artificial explicable).\n",
        "\n",
        "Centrándonos en la segunda, la evaluación de la capacidad de generalización y producción de conocimiento útil y aprovechable, las técnicas de evaluación van a depender de la tipología de problema que se esté resolviendo, por lo que existirán técnicas de evaluación de modelos de clasificación (y categorización), regresión, agrupamiento (*clustering*), reglas de asociación, etc. A continuación detallamos para cada tipología cuáles son las técnicas más utilizadas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.1. Evaluación de Clasificadores (y Categorizadores)**\n",
        "\n",
        "La evaluación de los modelos de clasificación (y categorización) se basa en el siguiente esquema. Como se puede observar, el modelo se construye con unos datos de entrenamiento, a partir de los cuales aprende a generalizar, y posteriormente se evalúa con unos datos de prueba o evaluación (*test*).\n",
        "\n",
        "\n",
        "\n",
        "![INTRO_MLProcess](https://tecno-academy.s3.eu-west-1.amazonaws.com/ML/DT/mlprocess.png \"Proceso de aprendizaje y evaluación de modelos de aprendizaje automático\")\n",
        "\n",
        "<small>*FUENTE: Elaboración propia*</small>\n",
        "\n",
        "Los datos de evaluación deben ser diferentes a los datos de entrenamiento: nunca antes han debido ser vistos por el modelo, para evitar así el sobreajuste, y que nos ayude a determinar con mayor precisión la calidad del modelo cuando se aplique a nuevas situaciones (capacidad de generalización).\n",
        "\n",
        "###**5.1.1. Métodos de Partición**\n",
        "\n",
        "Cuando únicamente tenemos un conjunto de datos, existen diferentes métodos de partición para conseguir sendos conjuntos de entrenamiento y evaluación. Es imprescindible que cualquiera de estos métodos garantice una total separación entre los datos de entrenamiento y de evaluación para evitar lo que se conoce como sobreajuste: si existen datos en el conjunto de evaluación que fueron utilizados para entrenar los modelos, al evaluar con ellos, el modelo podrá dar mejores resultados de los que daría en un entorno en producción con nuevos datos por haber aprendido sobreajustándose a los mismos.\n",
        "\n",
        "Entre los diferentes métodos de partición, destacan los tres siguientes:\n",
        "\n",
        "* ***Split***: Se divide el conjunto de datos en dos subconjuntos, entrenamiento y pruebas, con una ratio prefijada que generalmente resulta ser 30/70. Es decir, el 30% de los datos se utiliza para entrenamiento y el 70% restante para evaluación (aunque existen múltiples configuraciones dependiendo del tamaño de los datos y el modelo utilizado, como 20/80 o incluso 80/20, 70/30, etc.).\n",
        "\n",
        "* ***Cross-validation*** o **validacion cruzada**, llamada también ***n-fold cross-validation*** o **validación cruzada en n capas**: Consiste en realizar *n* particiones de los datos (como las del caso anterior) de los datos de entrenamiento y evaluación, donde cada vez se toman *1/n* elementos para entrenamiento y *9/n* elementos para evaluación (estas proporciones pueden variar e incluso admitir repetición de elementos entre iteracciones). Un valor común de *n* es 10, aunque en los casos más costososo (o donde se dispone de pocos datos) se suele reducir a 5. El objetivo de la validación cruzada es evitar el posible sesgo que pudiera tener una partición cualquiera como en el caso del ***split***, realizándolo múltiples veces y obteniendo la media. Es importante remarcar que uno de los errores más comunes con la validación cruzada es la de entrenar el modelo con todos los datos y evaluar posteriormente por este método, en lugar de, como se debe realizar, reentrenar y evaluar los modelos con los datos de cada partición. \n",
        "\n",
        "* ***Bootstrap***: Cuando el número de ejemplos de los que se dispone no es muy elevado, se puede utilizar esta técnica para aumentar la cantidad de los mismos de manera artificial. Para ello, se realiza un muestreo con reposición y posteriormente se aplica cualquiera de las técnicas vistas.\n",
        "\n",
        "\n",
        "##**5.1.2. Métodos de Evaluación**\n",
        "\n",
        "De las diferentes maneras en las que se puede evaluar un modelo de clasificación, destacan dos: la evaluación por **precisión** y la evaluación por **costes**.\n",
        "\n",
        "###**Evaluación por precisión**\n",
        "\n",
        "En la evaluación por precisión se prima que el modelo aumente la cantidad de ejemplos bien clasificados, para lo que se suele utilizar la medida ***accuracy***.\n",
        "\n",
        "* ***Accuracy* (precisión)**: Se define como el número de ejemplos correctamente clasificados dividido por el número total de ejemplos.\n",
        "\n",
        "* **Error muestral**: Se define como la inversa de la anterior: ***(1-accuracy)***, y proporciona el porcentaje de muestras o ejemplos mal clasificados.\n",
        "\n",
        "La medida ***accuracy*** (o desde la perspectiva contraria, el **error muestral**) permite fácilmente ver el rendimiento de un clasificador. Sin embargo, adolece de ciertos problemas. Por ejemplo, en el ámbito médico podríamos tener un clasificador que ante unos síntomas como mucosidad, fiebre y falta de\n",
        "apetito siempre diagnosticara gripe. Su accuracy sería muy cercana al 100%, pero ocurriría que un paciente con meningitis sería diagnosticado con gripe y podria morir. Esto es lo que se conoce como un **Falso Positivo**, y puede tener un coste muy superior a cualquier otro tipo de error. Así nace la\n",
        "necesidad de la evaluación por costes.\n",
        "\n",
        "###**Evaluación por costes**\n",
        "\n",
        "En la evaluación por costes prima que el modelo efectúe una predicción minimizando el coste (riesgo) de la misma. Para la evaluación por costes conviene construir una matriz con los posibles errores que se pueden producir. Es lo que se conoce como matriz de confusión. Supongamos un clasificador binario que clasifique a un paciente como meningitis sí (caso positivo) o no (caso negativo). La matriz de confusión quedaría de la siguiente manera:\n",
        "\n",
        "\n",
        "![INTRO_ConfussionMatrix](https://tecno-academy.s3.eu-west-1.amazonaws.com/ML/DT/confussion_matrix.png \"Matriz de confusión\")\n",
        "\n",
        "<small>*FUENTE: Elaboración propia*</small>\n",
        "\n",
        "El significado de las letras en la matriz es el siguiente:\n",
        "\n",
        "* ***a*** representa los casos que han sido correctamente predichos como casos negativos (pacientes sin meningitis que se han clasificado como que no padecen meningitis).\n",
        "* ***b*** representa los casos que incorrectamente se han clasificado como positivos (pacientes sin meningitis clasificados como que padecen la enfermedad).\n",
        "* ***c*** representa los casos que incorrectamente se han clasificado como negativos (pacientes con meningitis diagnosticados erróneamente como que no padecen meningitis).\n",
        "* ***d*** representa los casos que correctamente se han clasificado como positivos (pacientes con meningitis que correctamente se han identificado como tales).\n",
        "\n",
        "Asociado a cada uno de los valores ***a***, ***b***, ***c*** y ***d*** tenemos asociado un coste, con lo que deberemos multiplicar cada uno de los valores anteriores por su coste y quedarnos con aquel clasificador que minimice el\n",
        "resultado. Es importante notar que nos referimos a coste como función que asigna mayores pesos a los peores casos, no tiene por qué corresponderse con coste económico. Sin embargo, traducirlo\n",
        "a coste económico suele simplificar su entendimiento y facilitar la toma de decisiones.\n",
        "\n",
        "En el caso de que no sea posible disponer de una matriz de costes para aprender los modelos, se hace uso de la técnica del **análisis ROC (*Receiver Operating Characteristic*)**. Para ello se calculan las siguientes ratios a partir de la matriz de confusión:\n",
        "\n",
        "* ***True positive (TP)*** o verdaderos positivos, es la proporción de casos positivos que son correctamente clasificados.\n",
        "\n",
        "$$ TP = \\frac{d}{c+d} $$\n",
        "\n",
        "* ***False positive (FP)*** o falsos positivos, es la proporción de casos negativos que fueron incorrectamente clasificados como positivos.\n",
        "\n",
        "$$ FP = \\frac{b}{a+b} $$\n",
        "\n",
        "* ***True negative (TN)*** o verdaderos negativos, es la proporción de casos negativos que fueron correctamente clasificados.\n",
        "\n",
        "$$ TN = \\frac{a}{a+b} $$\n",
        "\n",
        "* ***False negative (FN)*** o falsos negativos, es la proporción de casos positivos que fueron incorrectamente clasificados como negativos.\n",
        "\n",
        "$$ FN = \\frac{c}{c+d} $$\n",
        "\n",
        "Y con ellas se representa una curva que confronte los ***False positive (FP)*** frente a los ***True positive (TP)*** en un espacio real de dos dimensiones con valores entre 0 y 1. Un clasificador será mejor cuanta más área cubra bajo la curva ***ROC***.\n",
        "\n",
        "###**Medidas alternativas**\n",
        "\n",
        "Tomadas de otras áreas como la de la recuperación de información (*IR* o *Information Retrieval*) y a partir de la matriz de\n",
        "confusión presentada anteriormente y las medidas *TP*, *FP*, *TN*, *FN*, se dispone de otra serie de medidas que permiten destacar diferentes aspectos del funcionamiento de los clasificadores. Concretamente:\n",
        "\n",
        "* ***Precision* (precisión)**: Indica la habilidad del clasificador para no asignar como positiva una muestra que es negativa. En el ejemplo, sería la capacidad del clasificador para no determinar que un paciente tiene meningitis cuando no la tiene. Se define como la relación entre los verdaderos positivos (TP) frente a la suma de verdaderos positivos (*TP*) y falsos\n",
        "positivos (*FP*).\n",
        "\n",
        "$$ precision = \\frac{TP}{TP+FP} $$\n",
        "\n",
        "* ***Recall* (alcance, recuerdo)**: Indica la habilidad del clasificador para encontrar todas las muestras positivas, es decir, la capacidad de clasificar correctamente a todos los pacientes que tienen meningitis y no descartarlos como que no la tienen. Se define como la relación entre el número de verdaderos positivos (*TP*) frente a la suma de verdaderos positivos (*TP*)\n",
        "y falsos negativos (*FN*).\n",
        "\n",
        "$$ recall = \\frac{TP}{TP+FN} $$\n",
        "\n",
        "* ***F-score***: Puesto que evaluar un modelo en base a dos medidas puede resultar complejo, especialmente a la hora de comparar diferentes sistemas, se define una medida que combina ambas, por regla general, como la **media armónica**, aunque se puede decidir efectuar un ajuste de peso diferente según convenga. Por ejemplo, si se le da más importancia a no dejar de diagnosticar un caso de meningitis frente a equivocarse y diagnosticar como meningitis un caso que no lo es, se optaría por incrementar el peso correspondiente a recall.\n",
        "\n",
        "$$ F-score = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall} $$\n",
        "\n",
        "###**Clasificación multiclase**\n",
        "\n",
        "Cuando se tiene más de dos clases, la matriz de confusión y los cálculos se complican un poco más, pero conceptualmente se seguiría el mismo procedimiento, calculando los valores de *TP*, *TN*, *FP*, y *FN* para cada una de las clases, y derivando el resto de métricas desde ellos. Para ello, aplicaríamos la siguiente lógica. Para el cálculo de las métricas que llevan al cálculo de la precisión, nos fijaríamos en los casos en los que el clasificador hizo una predicción y acertó o falló respectivamente:\n",
        "\n",
        "* Cuando el clasificador predijo la clase 0, en $n$ ocasiones acertó, fallando en $m$ ocasiones que es la suma de los valores en la matriz de confusión en los que el clasificador predijo las otras clases (revisión vertical o por filas).\n",
        "\n",
        "Para el cálculo del recuerdo/alcance (*recall*), nos fijaríamos en los casos en los que el clasificador tuvo que haber predecido algo, y realmente lo hizo o falló:\n",
        "\n",
        "* Cuando el clasificador debía haber predecido la clase 0, en $n$ ocasiones lo hizo correctamente, fallando en $m$ ocasiones que sería la suma de las celdas en la matriz de confusión en las que el clasificador predijo las otras clases (revisión horizontal o por columnas).\n",
        "\n",
        "Haciendo esto para clada clase, obtendríamos las métricas de *precision*, *recall* y *f-measure* para cada clase. \n",
        "\n",
        "###**Desequilibrio entre clases**\n",
        "\n",
        "Para computar las métricas generales de rendimiento del modelo, existen dos aproximaciones: ***micro-average*** y  ***macro-average***:\n",
        "\n",
        "* ***Macro-average***, cuando se computa la media independientemente de cada clase, y tomando entonces la media de las métricas anteriores.\n",
        "\n",
        "* ***Micro-average***, cuando se agrega la contribución de todas las clases para computar la media. Se suele utilizar cuando las clases están desequilibradas pues pondera la contribución de cada una a la métrica final.\n",
        "\n",
        "###**Correspondencia con otras métricas**\n",
        "\n",
        "Sabías que *Precision* y *Recall* serían lo mismo que las métricas *Sensibilidad* y *Especificidad* que se utilizan en medicina:\n",
        "\n",
        "* [Precision y Recall en la Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
        "\n",
        "* [Sensibilidad y Especificidad en la Wikipedia](https://es.wikipedia.org/wiki/Sensibilidad_y_especificidad)\n",
        "\n",
        "\n",
        "<br/>\n",
        "<p><mark>RECUERDA</mark></p>\n",
        "<hr>\n",
        "\n",
        "Estos conceptos los estudiamos en el Módulo de Fundamentos de Estadística, en la parte de Probabilidad."
      ],
      "metadata": {
        "id": "di2VeGaUVmUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **5.2. Evaluación de Modelos de Regresión**\n",
        "\n",
        "Los modelos de regresión se diferencian de los de clasificación en que, en lugar de asignar una clase única y nominal, se puede asignar un valor en un intervalo numérico continuo. La evaluación\n",
        "en este tipo de técnicas trata de encontrar un valor que proporcione la similitud entre el valor predicho y el valor real, para un conjunto de ejemplos de validación.\n",
        "\n",
        "Dado un conjunto de pruebas $T$ de $n$ ejemplos, el vector y de resultados predichos por el modelo aprendido, y el vector $ \\hat{y}$ de valores reales para cada ejemplo de pruebas (***ground truth***), el valor $\\hat{x}$ como la media de los valores predichos, y el valor $\\hat{y}$ como la media de los valores reales de regresión, las medidas más utilizadas para evaluar el modelo de regresión son las siguientes:\n",
        "\n",
        "* **Error cuadrático medio (*MSE, Mean Squared Error*)**: consiste en sumar los errores cuadráticos entre la salida del modelo y la función real:\n",
        "\n",
        "$$ MSE = \\frac{1}{n} \\sum_1^n{(y_i - \\hat{y_i})^2} $$\n",
        "\n",
        "* **Raíz del error cuadrático medio (*RMSE, Root Mean Squared Error*)**, que consiste en realizar la raíz cuadrada de la medida **MSE** para normalizar a la magnitud real de los errores (ya que con **MSE** efectuamos el cuadrado):\n",
        "\n",
        "$$ RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_1^n{(y_i - \\hat{y_i})^2}} $$\n",
        "\n",
        "* **Error absoluto medio (*MAE, Mean Absolute Error*)**, que trata de limitar el peso de los errores más extremos:\n",
        "\n",
        "$$ MAE = \\frac{1}{n} \\sum_1^n{|y_i - \\hat{y_i}|} $$\n",
        "\n",
        "* **Error cuadrático relativo (*RSE, Root Squared Error*)**, que pretende dar el mismo peso a errores de magnitud 10 en una predicción de 100, que errores de 1 en una predicción de 10.\n",
        "\n",
        "$$ RSE = \\frac{1}{n} \\sum_1^n{\\frac{(y_i - \\hat{y_i})^2}{(y_i - \\hat{y})^2}} $$\n",
        "\n",
        "* **Correlación producto-momento de Pearson (*PC, Pearson Product-Moment Correlation*)**: aunque no es una medida de evaluación específica de la regresión, ha sido utilizada\n",
        "en el estado del arte de tareas que involucran la regresión con una buena aceptación académica. El ***PC*** o **coeficiente de Pearson** como también se le conoce, proporciona una medida de correlación entre dos variables en un rango de entre $[-1,1]$ y se formula sobre una muestra $r$ como:\n",
        "\n",
        "$$ r = \\frac{\\sum_1^n{(x_i-\\hat{x})(y_i-\\hat{y})}}{\\sum_1^n{(x_i-\\hat{x})^2 \\sum_i^n{(y_i-\\hat{y})^2}}} $$"
      ],
      "metadata": {
        "id": "pfiDNb90VqKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.3. Evaluación de Modelos de Agrupamiento (Clustering)**\n",
        "\n",
        "En el caso del *clustering* no se dispone de etiquetas asociadas a los datos por lo que la evaluación hará uso del concepto de **verosimilitud (*likelihood*)** que implicará maximizar un valor determinado de similitud (inverso al concepto de distancia) entre los elementos agrupados conjuntamente. Es decir, minimizar la distancia (e.g. el error cuadrático) entre cada ejemplo $x_i$ y el centroide del grupo $c_k$ al que se asigna:\n",
        "\n",
        "$$ D = argmin \\sum_1^n{|x_i - c_k|^2} $$\n",
        "\n",
        "También se suele utilizar el concepto de **entropía**, que define la cantidad de información que aporta el modelo, y su objetivo en dicho caso es maximizarla."
      ],
      "metadata": {
        "id": "Fn1G2WqPVqEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.4. Evaluación de Reglas de Asociación**\n",
        "\n",
        "Las reglas de asociación se construyen sobre datos que no tenemos etiquetados. Son modelos descriptivos por lo que no se pueden aplicar las mismas técnicas que en los modelos predictivos.\n",
        "\n",
        "\n",
        "En el caso de las reglas, se utilizan principalmente las siguientes dos medidas para evaluarlas:\n",
        "\n",
        "* **Cobertura**, o **soporte** de la regla $X$, que es el número de ejemplos sobre los que la regla se puede aplicar.\n",
        "\n",
        "$$ supp(X) =  \\frac{|\\{t \\in T; X \\sqsubseteq t\\}|}{|T|} $$\n",
        "\n",
        "* **Confianza**, o **precisión** de la regla $X \\Rightarrow  Y$, que es el porcentaje de veces que la regla se cumple cuando se puede aplicar.\n",
        "\n",
        "$$ conf(X \\Rightarrow Y) = \\frac{supp(X \\cup Y)}{supp(X)} $$\n",
        "\n",
        "Por ejemplo, en un conjunto de datos con 100.000 ejemplos donde una regla aplica 55.000 veces su lado izquierdo y 40.000 veces su lado derecho, tendremos una cobertura del 55% (55.000 veces de las 100.000) y una confianza del 73% (40.000 veces de entre 55.000).\n",
        "\n",
        "Otra medida que se suele utilizar es **lift**:\n",
        "\n",
        "* **Lift** de la regla $X \\Rightarrow  Y$, que expresa cuál es la proporción del soporte observado de un conjunto de datos respecto del soporte teórico de ese conjunto dado el supuesto de independencia.\n",
        "\n",
        "$$ lift(X \\Rightarrow  Y) = \\frac{supp(X \\cup Y)}{supp(X) \\cdot supp(Y)} $$\n",
        "\n"
      ],
      "metadata": {
        "id": "1NqwABPbVpye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.5. Sobreajuste y Subajuste**\n",
        "\n",
        "Cuando se entrenan modelos mediante algoritmos de aprendizaje automático hay que prestar atención a dos efectos que pueden hacer que el rendimiento del modelo no sea el esperado: el sobreajuste (*overfitting*) y el subajuste (*underfitting*): \n",
        "\n",
        "\n",
        "**Subajuste (*Underfitting*)**\n",
        "\n",
        "Se produce subajuste cuando el modelo no es capaz de ajustarse a la variabilidad de los datos de entrenamiento, resultando en un modelo de bajo rendimiento (en términos de precisión, $R^2$ o cualquier otra medida de evaluación que utilicemos), tanto en los datos de evaluación como en los propios de entrenamiento. \n",
        "\n",
        "\n",
        "**Overfitting (sobreajuste)**\n",
        "\n",
        "Se produce sobreajuste cuando el modelo se ajusta en exceso a los datos de entrenamiento y por lo tanto pierde la capacidad de generalizar a datos nunca vistos anteriormente. En este caso, el rendimiento (en términos de precisión, $R^2$, o cualquier otra medida de evaluación que utilicemos) es muy elevada en los datos de entrenamiento pero decae significativamente en los datos de evaluación.\n"
      ],
      "metadata": {
        "id": "GEHjsPd9vWPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IDEAS CLAVE**\n",
        "<br>\n",
        "<hr>\n",
        "<p> <h1> <center> <strong> Aprendizaje Automático </center> </strong> </h1> </p>\n",
        "<hr>\n",
        "<br> \n",
        "\n",
        "* El **aprendizaje automático** es un enfoque para la inteligencia artificial que implica enseñar a las computadoras a **aprender de datos** en lugar de programarlas explícitamente para realizar una tarea.\n",
        "\n",
        "* Hay tres tipos principales de aprendizaje automático: **supervisado**, **no supervisado** y **por refuerzo**. El aprendizaje supervisado implica enseñar al modelo utilizando ejemplos de entrada y salida conocidos. Por ejemplo, la clasificación, la categorización y la regresión. El aprendizaje no supervisado implica encontrar patrones en los datos sin una salida conocida. Por ejemplo, el agrupamiento o las reglas de asociación. El aprendizaje por refuerzo implica enseñar al modelo a tomar decisiones basadas en recompensas y castigos.\n",
        "\n",
        "* El **entrenamiento** y la **evaluación** dos dos etapas críticas en el aprendizaje automático. El modelo se entrena en un conjunto de datos de entrenamiento y se evalúa en un conjunto de datos de prueba para verificar su rendimiento en función de una métrica de evaluación. Existen muchas y muy variadas, dependiendo del tipo de modelo a evaluar y de la propia distribución de los datos.\n",
        "\n",
        "* El ajuste excesivo (**sobreajuste** u ***overfitting***) y el ajuste insuficiente (**subajuste** o ***underfitting***) son problemas comunes en el aprendizaje automático. El sobreajuste ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a datos nuevos no vistos previamente, mientras que el subajuste ocurre cuando el modelo es demasiado simple para capturar los patrones en los datos.\n",
        "\n",
        "* El aprendizaje automático tiene muchas aplicaciones, como el **procesamiento del lenguaje natural**, la **visión por computador**, la **detección de fraude**, la **optimización de la cadena de suministro** y la **personalización del contenido**.\n",
        "\n",
        "* Para trabajar en aprendizaje automático, se necesitan habilidades en **matemáticas**, **estadística** y **programación**. **Python** es uno de los lenguajes de programación más populares para el aprendizaje automático y hay muchas bibliotecas de aprendizaje automático disponibles, como **TensorFlow**, **Keras** y **Scikit-Learn**.\n"
      ],
      "metadata": {
        "id": "lSdsrq7ReWMc"
      }
    }
  ]
}